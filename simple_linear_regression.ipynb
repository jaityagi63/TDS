{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3hQyb7SWEzixWwrXhVS3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaityagi63/TDS/blob/master/simple_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "formula for Simple linear regression (closed solution)\n",
        "\n",
        "$$\n",
        "m = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "b = \\bar{y} - m \\cdot \\bar{x}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "VhhRhi42_s06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6jeiuOnh_ok"
      },
      "outputs": [],
      "source": [
        "class LR_function:\n",
        "    def __init__(self):\n",
        "        self.m = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, x_train, y_train):\n",
        "        num, den = 0, 0\n",
        "        x_mean = x_train.mean()\n",
        "        y_mean = y_train.mean()\n",
        "\n",
        "        for i in range(x_train.shape[0]):\n",
        "            num += (x_train[i] - x_mean) * (y_train[i] - y_mean)\n",
        "            den += (x_train[i] - x_mean) ** 2\n",
        "\n",
        "        self.m = num / den\n",
        "        self.b = y_mean - self.m * x_mean\n",
        "\n",
        "        print(f'value of m is: {self.m}')\n",
        "        print(f'value of b is: {self.b}')\n",
        "        return self.m, self.b\n",
        "\n",
        "    def predict(self, x_test):\n",
        "        return self.m * x_test + self.b\n",
        "\n",
        "    def show_predictions(self, x_train, y_train, x_test):\n",
        "        self.fit(x_train, y_train)\n",
        "        y_pred = self.predict(x_test)\n",
        "        print(f'y_test (predicted): {y_pred}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = LR_function()\n"
      ],
      "metadata": {
        "id": "G9sir2kYi_Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5NbBKrFHkji3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array([1, 2, 3, 4, 5])\n",
        "y_train = np.array([2, 4, 5, 4, 5])\n"
      ],
      "metadata": {
        "id": "l7YHxsyWpFqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one.fit(x_train , y_train )"
      ],
      "metadata": {
        "id": "A35-xHdzlE1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c77cff-f840-4af8-8872-621a98e87821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 0.6\n",
            "value of b is: 2.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.6), np.float64(2.2))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.array([6, 7, 8, 9, 10])\n",
        "one.show_predictions(x_train,y_train,x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZIt3wjkSSsS",
        "outputId": "6bb23772-a84b-4bbf-8db9-cee8affe08f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 0.6\n",
            "value of b is: 2.2\n",
            "y_test (predicted): [5.8 6.4 7.  7.6 8.2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.8, 6.4, 7. , 7.6, 8.2])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "metric for linear regression\n",
        "1. MAE = mean abs error\n",
        "2. MSE = mean squared error\n",
        "3. RMSE = root mean squared error\n",
        "4. R2 score = determination score\n",
        "5. adjusted R2 square"
      ],
      "metadata": {
        "id": "GiHbhOpF-0nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Absolute Error (MAE)\n",
        "\n",
        "The **Mean Absolute Error (MAE)** is a commonly used evaluation metric for regression models. It measures the average magnitude of the errors in a set of predictions, without considering their direction. The formula for MAE is:\n",
        "\n",
        "$$\n",
        "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
        "$$\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "- \\( y_i \\): Actual value for the \\( i \\)-th data point  \n",
        "- \\( \\hat{y}_i \\): Predicted value for the \\( i \\)-th data point  \n",
        "- \\( n \\): Total number of data points  \n",
        "- \\( |y_i - \\hat{y}_i| \\): Absolute difference between the actual and predicted values\n",
        "\n",
        "#### Key Points:\n",
        "\n",
        "- MAE gives an idea of how far predictions are from the actual values on average.\n",
        "- It is expressed in the same units as the target variable.\n",
        "- MAE is easy to interpret and less sensitive to outliers compared to other metrics like Mean Squared Error (MSE).\n",
        "\n",
        "A lower MAE value indicates better model performance.\n"
      ],
      "metadata": {
        "id": "3d75EqWgB3Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MAE(LR_function):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.y_pred = None\n",
        "        self.mae = None\n",
        "\n",
        "    def calculate_mae(self, x_train, y_train, x_test, y_test):\n",
        "        self.fit(x_train, y_train)\n",
        "\n",
        "        self.y_pred = self.predict(x_test)\n",
        "\n",
        "        absolute_errors = abs(self.y_pred - y_test)\n",
        "        self.mae = absolute_errors.mean()\n",
        "\n",
        "        print(f\"Predictions: {self.y_pred}\")\n",
        "        print(f\"Mean Absolute Error (MAE): {self.mae}\")\n",
        "        return self.mae\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVUCnwEiQO9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "x_train = np.array([1, 2, 3, 4, 5])\n",
        "y_train = np.array([2.1, 3.9, 6.2, 7.8, 9.7])\n",
        "\n",
        "x_test = np.array([6, 7, 8])\n",
        "y_test = np.array([11.8, 14.5, 16.1])\n",
        "\n",
        "model = MAE()\n",
        "model.calculate_mae(x_train, y_train, x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNCOr_kIUs6x",
        "outputId": "0e6c213e-f13f-4fe3-8fe8-a807b32c5529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 1.9099999999999997\n",
            "value of b is: 0.21000000000000085\n",
            "Predictions: [11.67 13.58 15.49]\n",
            "Mean Absolute Error (MAE): 0.5533333333333358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.5533333333333358)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Squared Error (MSE)\n",
        "\n",
        "The **Mean Squared Error (MSE)** is a popular metric used to evaluate the performance of regression models. It measures the average of the squared differences between actual and predicted values.\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "- \\( y_i \\): Actual value for the \\( i \\)-th data point  \n",
        "- \\( \\hat{y}_i \\): Predicted value for the \\( i \\)-th data point  \n",
        "- \\( n \\): Total number of data points  \n",
        "- \\( (y_i - \\hat{y}_i)^2 \\): Squared error for each prediction\n",
        "\n",
        "#### Key Points:\n",
        "\n",
        "- MSE gives a higher penalty to larger errors due to squaring.\n",
        "- It is sensitive to outliers.\n",
        "- The lower the MSE, the better the model's predictions align with the actual data.\n",
        "- Unlike MAE, MSE does not maintain the same unit as the target variable—it squares the unit.\n",
        "\n",
        "MSE is often used when large errors are particularly undesirable.\n"
      ],
      "metadata": {
        "id": "xcLxvpRSD1La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MSE(LR_function):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.y_pred = None\n",
        "        self.mse = None\n",
        "\n",
        "    def calculate_mse(self, x_train, y_train, x_test, y_test):\n",
        "        # Train the model\n",
        "        self.fit(x_train, y_train)\n",
        "\n",
        "        # Predict on test data\n",
        "        self.y_pred = self.predict(x_test)\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        squared_errors = (self.y_pred - y_test) ** 2\n",
        "        self.mse = squared_errors.mean()\n",
        "        return self.mse\n"
      ],
      "metadata": {
        "id": "2fu5puDJWLFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Noisy training data\n",
        "x_train = np.array([1, 2, 3, 4, 5])\n",
        "y_train = np.array([2.2, 3.8, 6.3, 8.1, 10.2])\n",
        "\n",
        "# Slightly off test data\n",
        "x_test = np.array([6, 7, 8])\n",
        "y_test = np.array([12.1, 13.9, 16.5])\n",
        "\n",
        "# Instantiate and use MSE class\n",
        "model = MSE()\n",
        "model.calculate_mse(x_train, y_train, x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cdM364_WWK6",
        "outputId": "f0277405-cd40-4ca2-c41d-4c0b18a9d480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 2.03\n",
            "value of b is: 0.02999999999999936\n",
            "Mean Squared Error (MSE): 0.060200000000000135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.060200000000000135)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Root Mean Squared Error (RMSE)\n",
        "\n",
        "The **Root Mean Squared Error (RMSE)** is a commonly used metric to evaluate the accuracy of a regression model. It is the **square root** of the Mean Squared Error (MSE), which makes it easier to interpret because it is in the **same units** as the target variable.\n",
        "\n",
        "$$\n",
        "\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 }\n",
        "$$\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "- \\( y_i \\): Actual value for the \\( i \\)-th data point  \n",
        "- \\( \\hat{y}_i \\): Predicted value for the \\( i \\)-th data point  \n",
        "- \\( n \\): Total number of data points  \n",
        "- \\( (y_i - \\hat{y}_i)^2 \\): Squared error for each prediction\n",
        "\n",
        "#### Key Points:\n",
        "\n",
        "- RMSE gives a **heavier penalty to large errors** (just like MSE), but its output is more interpretable since it has the **same units** as the original data.\n",
        "- It is **sensitive to outliers**, because it squares the errors.\n",
        "- A **lower RMSE** means better model performance.\n",
        "\n",
        "RMSE is often used when large prediction errors are particularly undesirable and interpretability is important.\n"
      ],
      "metadata": {
        "id": "scgww1jpFu_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSE(MSE):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rmse = None\n",
        "    def calculate_RMSE(self, x_train, y_train, x_test, y_test):\n",
        "      mse = self.calculate_mse(x_train,y_train,x_test,y_test)\n",
        "      rmse = np.sqrt(mse)\n",
        "      return rmse\n"
      ],
      "metadata": {
        "id": "RuqQtaPLYgs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Noisy training data\n",
        "x_train = np.array([1, 2, 3, 4, 5])\n",
        "y_train = np.array([2.2, 3.8, 6.3, 8.1, 10.2])\n",
        "\n",
        "# Slightly off test data\n",
        "x_test = np.array([6, 7, 8])\n",
        "y_test = np.array([12.1, 13.9, 16.5])\n",
        "\n",
        "# Instantiate and use MSE class\n",
        "model = RMSE()\n",
        "model.calculate_RMSE(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOc2XNnkaLo1",
        "outputId": "ae26ecb7-05a1-4a30-8310-5a122fa61c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 2.03\n",
            "value of b is: 0.02999999999999936\n",
            "Mean Squared Error (MSE): 0.060200000000000135\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.24535688292770622)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R² Score (Coefficient of Determination)\n",
        "\n",
        "The **R² score**, or **coefficient of determination**, is a statistical measure that shows how well a regression model explains the variability of the target variable.\n",
        "\n",
        "It ranges from **0 to 1** (and can be negative in some cases), where:\n",
        "- **1** means perfect prediction\n",
        "- **0** means the model does no better than simply predicting the mean\n",
        "- **< 0** means the model performs worse than the mean\n",
        "\n",
        "#### Formula:\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n",
        "$$\n",
        "\n",
        "\n",
        "R^2 = 1 - sum of squared Error in regression\\sum of squared Error in mean term\n",
        "\n",
        "#### Explanation:\n",
        "\n",
        "- \\( y_i \\): Actual value  \n",
        "- \\( \\hat{y}_i \\): Predicted value  \n",
        "- \\( \\bar{y} \\): Mean of the actual values  \n",
        "- \\( \\sum (y_i - \\hat{y}_i)^2 \\): Residual sum of squares (model error)  \n",
        "- \\( \\sum (y_i - \\bar{y})^2 \\): Total sum of squares (total variance in data)\n",
        "\n",
        "#### Key Points:\n",
        "\n",
        "- R² measures the proportion of the variance in the dependent variable that is **predictable from the independent variable(s)**.\n",
        "- The closer R² is to **1**, the better the model explains the data.\n",
        "- A **low or negative R²** means the model is not capturing the pattern in the data well.\n",
        "\n",
        "R² is a good quick-check metric, but it should be used along with MAE, MSE, or RMSE for a complete evaluation.\n"
      ],
      "metadata": {
        "id": "9T5dNm4mHZ4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class R2(LR_function):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.r2 = 0\n",
        "\n",
        "  def calculate_r2(self,x_train,y_train,x_test,y_test):\n",
        "    y_pred = self.show_predictions(x_train,y_train,x_test)\n",
        "    y_mean = np.mean(y_test)\n",
        "    numerator = np.sum((y_test - y_pred)**2)\n",
        "    denominator = np.sum((y_test - y_mean)**2)\n",
        "    self.r2 = 1 - (numerator/denominator)\n",
        "    print(f'value of r2: {self.r2}')\n",
        "    return self.r2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NK8AkqdXdrPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array([1, 2, 3, 4, 5])\n",
        "y_train = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "x_test = np.array([6, 7, 8])\n",
        "y_test = np.array([6, 7, 9])\n",
        "\n",
        "# Instantiate and test R2\n",
        "model = R2()\n",
        "r2_score = model.calculate_r2(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g9Bvb8xfYH5",
        "outputId": "ed00ef33-73b3-4be6-8dbe-99dc16ce1bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of m is: 0.6\n",
            "value of b is: 2.2\n",
            "y_test (predicted): [5.8 6.4 7. ]\n",
            "value of r2: 0.05714285714285716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjusted R² Score in Regression Analysis\n",
        "\n",
        "## What is R² (R-squared)?\n",
        "R², or the **coefficient of determination**, is a statistical measure in regression that explains how much of the variance in the dependent variable is predictable from the independent variables.\n",
        "\n",
        "- **Range:** 0 to 1\n",
        "- **Interpretation:**\n",
        "  - 0: The model explains none of the variability.\n",
        "  - 1: The model explains all the variability.\n",
        "\n",
        "However, R² **always increases** as you add more variables, even if those variables don't actually improve the model.\n",
        "\n",
        "---\n",
        "\n",
        "## What is Adjusted R²?\n",
        "\n",
        "**Adjusted R²** is a modified version of R² that adjusts for the number of predictors in the model. It penalizes the addition of irrelevant predictors and is more reliable for comparing models with a different number of variables.\n",
        "\n",
        "### Formula:\n",
        "\n",
        "\\[\n",
        "\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n - 1)}{n - p - 1} \\right)\n",
        "\\]\n",
        "\n",
        "Where:\n",
        "- \\( R^2 \\) = regular R-squared\n",
        "- \\( n \\) = number of observations\n",
        "- \\( p \\) = number of independent variables\n",
        "\n",
        "---\n",
        "\n",
        "## Key Differences: R² vs Adjusted R²\n",
        "\n",
        "| Feature         | R²         | Adjusted R²         |\n",
        "|----------------|------------|----------------------|\n",
        "| Increases with added variables | Always | Only if the variable improves the model |\n",
        "| Penalizes unnecessary predictors | No     | Yes                  |\n",
        "| Best for comparing models with different numbers of features | No | Yes |\n",
        "\n",
        "---\n",
        "\n",
        "## When to Use Adjusted R²\n",
        "\n",
        "- When you're comparing models with **different numbers of predictors**.\n",
        "- When you want to **prevent overfitting** from adding too many features.\n",
        "- In **multiple linear regression** problems.\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "- **Adjusted R²** helps in choosing a model that balances goodness-of-fit with model simplicity.\n",
        "- It is a more **trustworthy metric** than R² when you add more variables.\n",
        "\n",
        "> **Tip:** If Adjusted R² decreases when you add a variable, that variable likely isn't helping your model.\n",
        "\n"
      ],
      "metadata": {
        "id": "scuT-0XTkZvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class adjusted_r2(R2):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.adj_r2 = 0\n",
        "\n",
        "    def calculate_adjusted_R2(self, x_train, y_train, x_test, y_test):\n",
        "        r2 = self.calculate_r2(x_train, y_train, x_test, y_test)\n",
        "        n = x_train.shape[0]\n",
        "        p = x_train.shape[1]\n",
        "        if n - p - 1 == 0:\n",
        "            raise ValueError(\"Cannot calculate adjusted R² due to division by zero (n - p - 1 == 0).\")\n",
        "\n",
        "        self.adj_r2 = 1 - (1 - r2) * ((int(n) - 1) / (int(n) - int(p) - 1))\n",
        "        print(f'value of adjusted_R2: {self.adj_r2}')\n",
        "        return self.adj_r2\n"
      ],
      "metadata": {
        "id": "a6r7E7FVqMlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # (5, 1)\n",
        "y_train = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "x_test = np.array([6, 7, 8]).reshape(-1, 1)        # (3, 1)\n",
        "y_test = np.array([6, 7, 9])\n",
        "\n",
        "# Instantiate and compute adjusted R²\n",
        "model = adjusted_r2()\n",
        "adjusted_r2_value = model.calculate_adjusted_R2(x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpZm_PB1rCm6",
        "outputId": "df528549-c6ac-45d9-db29-c0998c42035c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "value of adjusted_R2: -0.2571428571428571\n"
          ]
        }
      ]
    }
  ]
}